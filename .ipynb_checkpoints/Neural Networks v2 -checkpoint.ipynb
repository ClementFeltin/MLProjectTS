{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pdb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Useful functions'''\n",
    "def sigmoid(z):\n",
    "    return 1/ (1+ np.exp(-z))  \n",
    "\n",
    "def sigmoidPrime(z):\n",
    "    return np.exp(-z) / ((1+np.exp(-z))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "'''Neural Network parameters'''\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self, inputLayerSize, outputLayerSize, hiddenLayerSize, Lambda):\n",
    "        #Define Hyperparameters:\n",
    "        self.inputLayerSize = inputLayerSize \n",
    "        self.outputLayerSize = outputLayerSize\n",
    "        \n",
    "        # hidden layers \n",
    "        self.nbhiddenLayers = len(hiddenLayerSize)\n",
    "        self.hiddenLayerSize = hiddenLayerSize\n",
    "        \n",
    "        self.Lambda = Lambda\n",
    "        \n",
    "        # weights matrices\n",
    "        # they are randomly initialized here\n",
    "        # we add +1 for the biais on each inputs of W\n",
    "        self.W = []\n",
    "        self.W.append(np.random.rand(self.inputLayerSize + 1,self.hiddenLayerSize[0]))\n",
    "        for i in range(self.nbhiddenLayers - 1):\n",
    "            self.W.append(np.random.rand(self.hiddenLayerSize[i] + 1,self.hiddenLayerSize[i+1]))\n",
    "        self.W.append(np.random.rand(self.hiddenLayerSize[-1] + 1,self.outputLayerSize))\n",
    "        \n",
    "        \n",
    "        # biais , no biais for inputs\n",
    "        self.biais = []\n",
    "        self.biais.append(np.zeros(1))\n",
    "        for i in range(self.nbhiddenLayers):\n",
    "            self.biais.append( np.random.randn(self.hiddenLayerSize[i], 1) )\n",
    "            \n",
    "            \n",
    "    def forward(self, X): \n",
    "        # propagate \n",
    "        self.z = []\n",
    "        self.a = []\n",
    "        X_copy = X\n",
    "        for i in range(self.nbhiddenLayers+1):\n",
    "            \n",
    "            z = np.dot(X_copy, self.W[i]) +self.biais[i]\n",
    "            a = sigmoid(z)\n",
    "      \n",
    "            self.z.append(z)\n",
    "            self.a.append(a)\n",
    "            \n",
    "            X_copy = a\n",
    "            \n",
    "        return self.a[-1]\n",
    "        \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)/X.shape[0] \n",
    "        # normlisation : + (self.Lambda/2)*(norm(self.W1)+norm(self.W2)) \n",
    "        return J     \n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        self.delta = []\n",
    "        self.dJdW = []\n",
    "        self.delta.insert(0, np.multiply(-(y-self.yHat), sigmoidPrime(self.z[-1])))\n",
    "        #Add gradient of regularization term:\n",
    "        self.dJdW.insert(0,np.dot(self.a[-2].T, self.delta[0])/X.shape[0] )\n",
    "                    # + self.Lambda*self.W2 regu\n",
    "        \n",
    "        for i in range(self.nbhiddenLayers-1,0,-1):            \n",
    "            self.delta.insert(0, np.dot(self.delta[0], self.W[i+1].T)*sigmoidPrime(self.z[i]))\n",
    "            #Add gradient of regularization term:\n",
    "            self.dJdW.insert( 0, np.dot(self.a[i-1].T, self.delta[0])/X.shape[0] )\n",
    "                             #+ self.Lambda*self.W1 regu\n",
    "        \n",
    "        self.delta.insert(0, np.dot(self.delta[0], self.W[1].T)*sigmoidPrime(self.z[0]))\n",
    "        #Add gradient of regularization term:\n",
    "        self.dJdW.insert( 0, np.dot(X.T, self.delta[0])/X.shape[0] )\n",
    "        \n",
    "    def getParams(self):\n",
    "        #get W1,W2,..Wi into a flat vector\n",
    "        params = np.concatenate([array.ravel() for array in NN.W])\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #unrolling of Wi... vectors\n",
    "        W_start = 0\n",
    "        W_end = self.hiddenLayerSize[0]*self.inputLayerSize\n",
    "        self.W = []\n",
    "        self.W.append(np.reshape(params[W_start: W_end], \\\n",
    "                            (self.inputLayerSize,self.hiddenLayerSize[0])))\n",
    "        for i in range(self.nbhiddenLayers -1):\n",
    "            W_start = W_end\n",
    "            W_end = W_end + self.hiddenLayerSize[i]* self.hiddenLayerSize[i+1]\n",
    "            self.W.append(np.reshape(params[W_start: W_end], \\\n",
    "                            (self.hiddenLayerSize[i],self.hiddenLayerSize[i+1])))\n",
    "                    \n",
    "        W_start = W_end\n",
    "        W_end = W_end + self.hiddenLayerSize[self.nbhiddenLayers -1]* self.outputLayerSize\n",
    "        self.W.append( np.reshape(params[W_start: W_end], \\\n",
    "                            (self.hiddenLayerSize[self.nbhiddenLayers -1],self.outputLayerSize)) )\n",
    "    \n",
    "    def computeGradients(self, X, y):\n",
    "        # get gradients into a flat vector\n",
    "        self.costFunctionPrime(X, y)\n",
    "        return np.concatenate([array.ravel() for array in self.dJdW])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "'''Trainer for the Neural Networks'''\n",
    "class Trainer(object):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "    \n",
    "    def callbackF(self, params):\n",
    "        # callback function keeping Cost in memory\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))  \n",
    "    \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        # function returning cost and grad\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X,y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "        return cost, grad\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \n",
    "        self.X= X\n",
    "        self.y= y\n",
    "        \n",
    "        # make empty list to store costs\n",
    "        self.J = []\n",
    "        params0 = self.N.getParams()\n",
    "        \n",
    "        # algo used here is L-BFGS. \n",
    "        options ={'maxiter' : 200000, 'disp':True}\n",
    "        \n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, \\\n",
    "                                jac = True, method ='BFGS', args = (X,y) \\\n",
    "                                 , callback=self.callbackF\n",
    "                                )\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Test of Neural Net'''\n",
    "n_samples = 1000\n",
    "inputLayerSize = 5 \n",
    "outputLayerSize = 1\n",
    "# hiddenLayerSize = 3\n",
    "Lambda = 0.0001 \n",
    "NN = Neural_Network(inputLayerSize = inputLayerSize, outputLayerSize = outputLayerSize, hiddenLayerSize = [1,4,5], Lambda = 0.0001  )\n",
    "T = Trainer(NN)\n",
    "X = np.random.rand(n_samples,inputLayerSize)\n",
    "y = np.random.rand(n_samples,outputLayerSize)\n",
    "T.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction for Electricity production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Data loading'''\n",
    "f_names_national = [\n",
    "    '2012 Conso Prod.csv',\n",
    "    '2013 Conso Prod.csv',\n",
    "    '2014 Conso Prod.csv',\n",
    "    '2015 Conso Prod.csv'\n",
    "]\n",
    "\n",
    "datas = []\n",
    "data_news = []\n",
    "for f_name in f_names_national:\n",
    "#     print(f_name)\n",
    "    data = pd.read_csv('data/'+ f_name, delimiter='\\t', encoding = \"ISO-8859-1\")\n",
    "    pd.set_option('max_columns', 100)\n",
    "    headers = list(data)\n",
    "    data = data[data.Consommation.notnull()]\n",
    "    data = data[data.Date.notnull()]\n",
    "    data['timestamp'] = [str(d) + ' ' + str(t) for d, t in zip(data['Date'].values, data['Heures'].values)]\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], format='%Y-%m-%d %H:%M')\n",
    "    datas.append(data)\n",
    "\n",
    "data_final = pd.concat(datas).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Plot of the Electricity Consumption in France over 3 years'''\n",
    "ts =pd.Series(data_final['Consommation'].values, index = data_final['timestamp'].values )\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "ax.plot(ts[::10].index, ts[::10])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "ax.set_title(\" Electricity consumption in France in MW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sorting values : le premier élement du data set est le plus récent : \n",
    "# y(t), y(t-1) etc... \n",
    "data_final = data_final.sort_values(by=['Date','Heures'], ascending=[False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''tau : paramètre de périodicité'''\n",
    "tau = 48 # 48 : on considère une corrélation de 24h. On pourrait prendre tau = 1 an \n",
    "            # afin de correler les données avec les données de l'année passée\n",
    "\n",
    "def data_labels(dataframe=data_final, field='Consommation', tau = tau):\n",
    "    X = dataframe[field].values\n",
    "    X_ = np.stack([np.roll(X,i) for i in range(49)], axis=1)\n",
    "\n",
    "    labels = X_[:,:1]\n",
    "    data = X_[:,1:]\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Training and CV sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the training set and the crossvalidation set.\n",
    "# two years of training, 1 year for cv \n",
    "data_train, labels_train = data_labels(dataframe = data_final[data_final['Date'] <= '2014-12-31'])\n",
    "data_test, labels_test = data_labels(dataframe = data_final[data_final['Date'] > '2014-12-31'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = X_train.shape[0]\n",
    "# inputLayerSize = 2 \n",
    "# outputLayerSize = 1\n",
    "# hiddenLayerSize = 3\n",
    "Lambda = 0.01 \n",
    "NN = Neural_Network(inputLayerSize = X_train.shape[1], outputLayerSize = 1, hiddenLayerSize = [20,20,10], Lambda = 0.01  )\n",
    "T = Trainer(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4d2b1b525ea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-493702adff91>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'disp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         _res = optimize.minimize(self.costFunctionWrapper, params0,                                 jac = False, method ='BFGS', args = (X,y)                                  , callback=self.callbackF\n\u001b[0m\u001b[1;32m     27\u001b[0m                                 )\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benlet/anaconda3/lib/python3.5/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[0;32m/home/benlet/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mgrad_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m     \u001b[0mgfk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benlet/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benlet/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[0;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benlet/anaconda3/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": [
    "T.train(X_train, Y_train)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(T.J)\n",
    "plt.plot(T.J)\n",
    "plt.grid(1)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f50e00eb9b0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAHUpJREFUeJzt3X+0Z3Vd7/Hnix9h4mLIS81kTiLxIzIbmoMIXCluKIjk\nzyw9KhpCItjCRr0Y3W6m5EV0AcFV1GSlEHnSzBS14AqZVA6Y5wC5chDvRS4IzFwJHSwcQOZ9/9j7\n1HcO58zM9zDzOed8eT7W+q41+/N97/39vGfmfL+vs/f+7p2qQpIkqZVdFnoCkiTpscXwIUmSmjJ8\nSJKkpgwfkiSpKcOHJElqyvAhSZKaMnxIkqSmDB+SJKkpw4ckSWrK8CFJkpoaOnwkOSrJFUnuTLI5\nyQu2Y52jk0wm2ZTkliSvmaVmWZL3Jbmrr7s5yXOHnZ8kSVrc5rPnY0/gRuB0YJs3hkmyL/BZ4Bpg\nFXAhcEmS5wzU7A5cDfwk8BLgQOA3gDvnMT9JkrSI5dHcWC7JZuBFVXXFVmrOBY6vqp8bGJsAllXV\n8/rl1wNvBn66qh6e94QkSdKi1+Kcj8Pp9moMugo4YmD5+cBa4OIk65N8NclZSTwnRZKkEbNbg9dY\nAWyYMbYB2CvJHlX1ALAf8EvA5cDxwP7A+/v5nT3bRpP8J+A44DZg006ZuSRJo+lxwL7AVVX1L61f\nvEX42B670AWS11V3HOiGJE8G3sIc4YMuePxpo/lJkjSKXgl8tPWLtggf64HlM8aWA/f1ez0A7gYe\nrC1PQFkHrEiyW1X9YJbt3gZw+eWXc/DBB+/gKS8ua9as4YILLljoaex09jla7HO02OdoWbduHa96\n1aug/yxtrUX4WEt3KGXQsf34tH8AxmfUHATcPUfwgP5Qy8EHH8zq1at3xDwXrWXLlo18j2Cfo8Y+\nR4t9jqwFOW1hPtf52DPJqiSH9EP79csr++fPSXLpwCof6GvOTXJQktOBlwLnD9S8H3hikouSHJDk\nBOAs4L3z6kqSJC1a89nzcSjwBbprfBRwXj9+KfBauhNMV04XV9VtfZi4ADgD+BZwclVdPVDzrSTH\n9TU30V3f4wLg3fOYnyRJWsSGDh9V9UW2ssekqk6aZexaYGwb270eOHLY+UiSpKXF62gsAePjM0+H\nGU32OVrsc7TYp3akR3WF04WUZDUwOTk5+Vg7OUiSpEdlamqKsbExgLGqmmr9+u75kCRJTRk+JElS\nU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JThQ5Ik\nNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0ZPiRJ\nUlOGD0mS1JThQ5IkNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOS\nJDVl+JAkSU0ZPiRJUlOGD0mS1JThQ5IkNWX4kCRJTRk+JElSU4YPSZLU1NDhI8lRSa5IcmeSzUle\nsB3rHJ1kMsmmJLckec1Wal/eb/eTw85NkiQtfvPZ87EncCNwOlDbKk6yL/BZ4BpgFXAhcEmS58xR\n+x7g2nnMS5IkLQG7DbtCVV0JXAmQJNuxymnArVV1Zr/89STPAtYAn58uSrILcDnwe8AvAMuGnZsk\nSVr8WpzzcThw9Yyxq4AjZoy9DdhQVR9uMCdJkrRAht7zMQ8rgA0zxjYAeyXZo6oe6PeEnER3WEaS\nJI2wFuFjq5I8AbgM+I2q+s6w669Zs4Zly7Y8QjM+Ps74+PgOmqEkSUvXxMQEExMTW4xt3LhxgWbT\nSdU2zxmde+VkM/CiqrpiKzVfBCar6k0DY78OXFBVP5JkFTAFPAxMn0MyfTjoYeCgqvrmLNtdDUxO\nTk6yevXqefcgSdJjzdTUFGNjYwBjVTXV+vVb7PlYCxw/Y+zYfhzgZuDpM55/J/AE4Azgjp06O0mS\n1NTQ4SPJnsD+/Mdeiv36vRf3VtUdSc4BnlRV09fy+ADwhiTnAn8MHAO8FHgeQFU9AHxtxmt8t3uq\n1s2jJ0mStIjN59suhwI3AJN01/k4j+6wydv751cAK6eLq+o24ATg2XTXB1kDnFxVM78BI0mSHgPm\nc52PL7KV0FJVJ80ydi0wNsRrPGIbkiRpNHhvF0mS1JThQ5IkNWX4kCRJTRk+JElSU4YPSZLUlOFD\nkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JThQ5IkNWX4kCRJTRk+\nJElSU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JTh\nQ5IkNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0Z\nPiRJUlOGD0mS1JThQ5IkNWX4kCRJTRk+JElSU0OHjyRHJbkiyZ1JNid5wXasc3SSySSbktyS5DUz\nnj8lybVJ7u0fn0/yjGHnJkmSFr/57PnYE7gROB2obRUn2Rf4LHANsAq4ELgkyXMGyn4R+ChwNHA4\ncAfwv5L8+DzmJ0mSFrHdhl2hqq4ErgRIku1Y5TTg1qo6s1/+epJnAWuAz/fbPHFwhSSnAL8CHANc\nPuwcJUnS4tXinI/DgatnjF0FHLGVdfYEdgfu3VmTkiRJC6NF+FgBbJgxtgHYK8kec6xzLnAnjwwt\nkiRpiRv6sMvOluS3gV8DfrGqHlzo+UiSpB2rRfhYDyyfMbYcuK+qHhgcTPIW4EzgmKr65+3Z+Jo1\na1i2bNkWY+Pj44yPj89/xpIkjYiJiQkmJia2GNu4ceMCzaaTqm1+YWXulZPNwIuq6oqt1LwLOL6q\nVg2MfRTYu6qeNzB2JnAWcGxV/eN2vPZqYHJycpLVq1fPuwdJkh5rpqamGBsbAxirqqnWrz+f63zs\nmWRVkkP6of365ZX98+ckuXRglQ/0NecmOSjJ6cBLgfMHtvlW4B3Aa4HbkyzvH3vOtzFJkrQ4zeeE\n00OBG4BJuut8nAdMAW/vn18BrJwurqrbgBOAZ9NdH2QNcHJVDZ5M+nq6b7d8Arhr4PHmecxPkiQt\nYvO5zscX2UpoqaqTZhm7FhjbyjpPHXYekiRpafLeLpIkqSnDhyRJasrwIUmSmjJ8SJKkpgwfkiSp\nKcOHJElqyvAhSZKaMnxIkqSmDB+SJKkpw4ckSWrK8CFJkpoyfEiSpKYMH5IkqSnDhyRJasrwIUmS\nmjJ8SJKkpgwfkiSpKcOHJElqyvAhSZKaMnxIkqSmDB+SJKkpw4ckSWrK8CFJkpoyfEiSpKYMH5Ik\nqSnDhyRJasrwIUmSmjJ8SJKkpgwfkiSpKcOHJElqyvAhSZKaMnxIkqSmDB+SJKkpw4ckSWrK8CFJ\nkpoyfEiSpKYMH5IkqSnDhyRJasrwIUmSmjJ8SJKkpgwfkiSpqaHDR5KjklyR5M4km5O8YDvWOTrJ\nZJJNSW5J8ppZan41ybok309yU5Ljh52bJEla/Oaz52NP4EbgdKC2VZxkX+CzwDXAKuBC4JIkzxmo\nORL4KPAh4BDg08CnkvzMPOYnSZIWsd2GXaGqrgSuBEiS7VjlNODWqjqzX/56kmcBa4DP92NnAH9d\nVef3y7/Xh5PfpAs5kiRpRLQ45+Nw4OoZY1cBRwwsH7EdNZIkaQQMvedjHlYAG2aMbQD2SrJHVT2w\nlZoV29r4V74C9923Q+YpSRI//MPwzGcu9CxGW4vwsVOdeuoaYNmM0fH+IUnScA44AG65ZaFnseNM\nTEwwMTGxxdjGjRsXaDadFuFjPbB8xthy4L5+r8fWatZva+Of+tQFPO1pqx/1JCVJAth994WewY41\nPj7O+PiWv5BPTU0xNja2QDNqEz7WAjO/NntsPz5Ycwxw0cDYc2bUzGrlSth//0c7RUmS1Mp8rvOx\nZ5JVSQ7ph/brl1f2z5+T5NKBVT7Q15yb5KAkpwMvBc4fqLkQeG6SN/U1vw+MAe+dT1OSJGnxms+3\nXQ4FbgAm6a7zcR4wBby9f34FsHK6uKpuA04Ank13fZA1wMlVdfVAzVrgFcDr+pqXAC+sqq/NY36S\nJGkRm891Pr7IVkJLVZ00y9i1dHsytrbdvwD+Ytj5SJKkpcV7u0iSpKYMH5IkqSnDhyRJasrwIUmS\nmjJ8SJKkpgwfkiSpKcOHJElqyvAhSZKaMnxIkqSmDB+SJKkpw4ckSWrK8CFJkpoyfEiSpKYMH5Ik\nqSnDhyRJasrwIUmSmjJ8SJKkpgwfkiSpKcOHJElqyvAhSZKaMnxIkqSmDB+SJKkpw4ckSWrK8CFJ\nkpoyfEiSpKYMH5IkqSnDhyRJasrwIUmSmjJ8SJKkpgwfkiSpKcOHJElqyvAhSZKaMnxIkqSmDB+S\nJKkpw4ckSWrK8CFJkpoyfEiSpKYMH5IkqSnDhyRJasrwIUmSmjJ8SJKkpuYVPpK8Ick3k3w/yXVJ\nnrEd9V9Lcn+SdUlOnKXmt5Lc3NfcnuT8JHvMZ36SJGnx2m3YFZK8DDgPeB3wZWANcFWSA6vqnlnq\nTwPeCZwCfAV4JvChJPdW1ef6mlcA5wC/DqwFDgQ+AmwG3jJ0V5IkadGaz56PNcAHq+qyqroZeD1w\nP/DaOepf1dd/oqpuq6qPAX8EvHWg5gjg76vqY1V1e1VdDfwZcNg85idJkhaxocJHkt2BMeCa6bGq\nKuBqugAxmz2ATTPGNgGHJdm1X/4SMDZ9+CbJfsDzgM8NMz9JkrT4DbvnYx9gV2DDjPENwIo51rkK\nOCXJaoAkhwInA7v326OqJoC3AX+f5EHgG8AXqurcIecnSZIWuaHP+ZiHs4HlwNokuwDr6c7nOJPu\nnA6SHA38Dt0hnC8D+wMXJbm7qv5gaxtfs2YNy5Yt22JsfHyc8fHxHduFJElL0MTEBBMTE1uMbdy4\ncYFm00l31GQ7i7vDLvcDv1JVVwyMfwRYVlUv3sq6u9KFkLuBU4F3VdXe/XPXAtdV1ZkD9a+kO1fk\nCXNsbzUwOTk5yerVq7e7B0mSHuumpqYYGxsDGKuqqdavP9Rhl6p6CJgEjpkeS5J++UvbWPfhqrqr\nP0fk5cBnBp5+PPCDGatM7xXJMHOUJEmL23wOu5wPfCTJJP/xVdvH0x1KIck5wJOq6jX98gF031q5\nHngi8CbgacCrB7b5GWBNkpv6ugOAdwBX1DC7ZiRJ0qI3dPioqo8n2YcuHCwHbgSOq6pv9yUrgJUD\nq+wKvJnu2h0PAV8Ajqyq2wdqzqbb03E28BPAt4ErgN8ddn6SJGlxm9cJp1V1MXDxHM+dNGP5ZmCr\nJ2VU1XTwOHs+85EkSUuH93aRJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JTh\nQ5IkNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0Z\nPiRJUlOGD0mS1JThQ5IkNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU\n4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JThQ5IkNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1ZfiQJElN\nGT4kSVJThg9JktSU4UOSJDU1r/CR5A1Jvpnk+0muS/KM7aj/WpL7k6xLcuIsNcuSvC/JXUk2Jbk5\nyXPnMz9JkrR47TbsCkleBpwHvA74MrAGuCrJgVV1zyz1pwHvBE4BvgI8E/hQknur6nN9ze7A1cB6\n4CXAXcBTgO/OpylJkrR4DR0+6MLGB6vqMoAkrwdOAF4LvHuW+lf19Z/ol2/r95S8FfhcP3YysDdw\neFU93I/dPo+5SZKkRW6owy79Hoox4Jrpsaoqur0WR8yx2h7Aphljm4DDkuzaLz8fWAtcnGR9kq8m\nOSuJ56RIkjRihv1w3wfYFdgwY3wDsGKOda4CTkmyGiDJoXR7OnbvtwewH/Cr/XyOB94BvBn4b0PO\nT5IkLXLzOewyrLOB5cDafk/GeuAjwJnA5r5mF7oA87p+T8oNSZ4MvKVfX5IkjYhhw8c9wMN0YWLQ\ncrpQ8QhVtYluz8epfd3dwKnA96rq233Z3cCDffCYtg5YkWS3qvrBXBNas2YNy5Yt22JsfHyc8fHx\n7e9KkqQRNTExwcTExBZjGzduXKDZdLLl5/12rJBcB1xfVW/sl0N3cuhFVfWe7dzG3wJ3VNWJ/fI7\ngfGq2m+g5o3Af62qJ8+xjdXA5OTkJKtXrx6qB0mSHsumpqYYGxsDGKuqqdavP58TOs8HfiPJq5P8\nNPAB4PF0h1JIck6SS6eLkxyQ5JVJ9k9yWJI/A57GludzvB94YpKL+voTgLOA986vLUmStFgNfc5H\nVX08yT50J4UuB24Ejhs4hLICWDmwyq50J48eCDwEfAE4sqpuH9jmt5IcB1wA3ATc2f95tq/uSpKk\nJWxeJ5xW1cXAxXM8d9KM5ZuBbR4XqarrgSPnMx9JkrR0eB0NSZLUlOFDkiQ1ZfiQJElNGT4kSVJT\nhg9JktSU4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JThQ5IkNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1\nZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JThQ5IkNWX4kCRJTRk+JElS\nU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJThg9JktSU4UOSJDVl+JAkSU0ZPiRJUlOGD0mS1JThQ5Ik\nNWX4kCRJTRk+JElSU4YPSZLUlOFDkiQ1ZfiQJElNGT4kSVJTho8lYGJiYqGn0IR9jhb7HC32qR1p\nXuEjyRuSfDPJ95Ncl+QZ21H/tST3J1mX5MSt1L48yeYkn5zP3EbRY+WHwT5Hi32OFvvUjjR0+Ejy\nMuA84G3AzwM3AVcl2WeO+tOAdwK/B/wM8PvA+5KcMEvtvsB7gGuHnZckSVoa5rPnYw3wwaq6rKpu\nBl4P3A+8do76V/X1n6iq26rqY8AfAW8dLEqyC3A5XUj55jzmJUmSloChwkeS3YEx4Jrpsaoq4Grg\niDlW2wPYNGNsE3BYkl0Hxt4GbKiqDw8zJ0mStLTsNmT9PsCuwIYZ4xuAg+ZY5yrglCSfrqqpJIcC\nJwO799vbkORZwEnAqiHm8jiAdevWDbHK0rRx40ampqYWeho7nX2OFvscLfY5WgY+Ox+3IBOoqu1+\nAD8ObAaeOWP8XGDtHOs8DrgEeAB4CLgDOAd4GPhR4AnArcBxA+t8GPjkNubyCqB8+PDhw4cPH/N+\nvGKYHLCjHsPu+biHLjQsnzG+HFg/2wpVtYluz8epfd3dwKnA96rq20lWAU8BPpMk/Wq7ACR5EDio\nqr45y6avAl4J3MYjD+tIkqS5PQ7Yl+6ztLn0exG2f4XkOuD6qnpjvxzgduCiqnrPdm7jb4E7qurE\nJHsAPzWj5J10e0TOAL5RVT8YapKSJGnRGnbPB8D5wEeSTAJfpvv2y+OBjwAkOQd4UlW9pl8+ADgM\nuB54IvAm4GnAqwGq6gHga4MvkOS73VM1+id0SJL0GDN0+Kiqj/fX9HgH3WGUG+nO1/h2X7ICWDmw\nyq7Am4ED6c75+AJwZFXd/mgmLkmSlqahD7tIkiQ9Gt7bRZIkNWX4kCRJTS3J8DHsje0WUpKzknw5\nyX1JNiT5yyQHzlL3jiR39Tff+3yS/Wc8v0eS9yW5J8n3knwiyY/NqPmRJH+aZGOS7yS5JMmeO7vH\n2ST57f4GgefPGF/yfSZ5UpI/6ed4f5KbkqyeUbOk+0yyS5Kzk9za9/C/k/zuLHVLrs8kRyW5Ismd\n/f/RFyxUX0lWJvlckn9Lsj7Ju9PdamKn9plktyTnJvmnJP/a11ya5MdHqc9Zaj/Q15wxin0mOTjJ\np5N8t/93vT7JkxdlnwtxcZFH8wBeRnddj1cDPw18ELgX2Geh5zbHfP8KOBE4GHg68Fm6a5P88EDN\nW/sefhn4WeBTwP8Bfmig5v39er9Id0O/LwF/N+O1/hqYAg4FjgRuAS5fgJ6fQXfhuBuA80epT2Bv\nunsPXUJ3q4GnAM8Gnjpiff4O8P+A5wI/CbwEuA/4zaXeZ9/TO4AX0l236AUznm/SF90vf1+lu87C\n04Hj+r/zP9jZfQJ79a/7K8D0NxKvA748YxtLus8ZdS+me0+6Azhj1Pqku2TFPXQX8fw54Kn9/+F9\nFmOfO+WHe2c++h+QCweWA3wLOHOh57ad89+H7iqxzxoYuwtYM7C8F/B94NcGlh8AXjxQc1C/ncP6\n5YP75Z8fqDkO+AGwomF/TwC+DvwS3TebBsPHku8TeBfwxW3UjEKfnwE+NGPsE8BlI9bnZh75Jt6k\nL+B4um8ADn44nAp8B9htZ/c5S82hdB9qTx61PoGfoLse1cF0vzycMfDcSPQJTACXbmWdRdXnkjrs\nkvnd2G6x2Zvukrb3AiR5Kt3Xkwd7uo/uuijTPR1K97XowZqv0/0wTdccDnynqm4YeK2r+9d65s5o\nZA7vAz5TVX8zODhCfT4f+EqSj6c7jDaV5JTpJ0eozy8Bx6S7Tg/prkT8n+n25I1Sn1to3NfhwFer\n6p6BmquAZXTXQmpt+r3pu/3yGCPQZ5IAlwHvrtmvHbXk++x7PAH4RpIr+/em65K8cKBsUfW5pMIH\nW7+x3Yr20xlO/x/kD4G/r6rpC6utoPuH3VpPy4EH+zfBuWpW0O36+ndV9TBdyGnyd5Pk5cAhwFmz\nPD0qfe4HnEa3d+dYut2YFyU5cWB+o9Dnu4CPATenu83BJPCHVfVnA/MbhT5natnXijleBxr3nu5K\n0+8CPlpV/zowh1Ho87fp+njvHM+PQp8/RrfX+a10vyA8B/hL4JNJjhqYw6Lpcz5XONX8XQz8DN1v\nkCOlP6npD4FnV9VDCz2fnWgXuuPi/71fvinJzwKvB/5k4aa1w72M7uaNL6e7AvEhwIVJ7qqqUerz\nMS/JbsCf04Wu0xd4OjtUkjG623T8/ELPZSeb3pHwqaq6qP/zPyU5ku696e8WZlpzW2p7Poa+sd1i\nkeS9wPOAo6vq7oGn1tOdt7K1ntYDP5Rkr23UzDxreVe6S9q3+LsZo7tL8VSSh5I8RHdS0xv735w3\nMBp93g3M3HW7ju6kTBidf893A++qqj+vqn+uqj8FLuA/9mqNSp8ztexr/RyvA416HwgeK4FjB/Z6\nTM9hqff5LLr3pTsG3peeApyf5NaBOSz1Pu+hOy9jW+9Ni6bPJRU++t+oJ4Fjpsf6QxnH0B2jXpT6\n4PFC4L/UjMvKV3fH3vVs2dNedMfXpnuapPuPNVhzEN1/qrX90Fpg7ySDCf8YujfS63dkP3O4mu7M\n50OAVf3jK8DlwKqqupXR6PMf6E7SGnQQ8H9hpP49H08X9Adtpn/PGKE+t9C4r7XA09PdrmLascBG\nZtzvamcYCB77AcdU1XdmlIxCn5fRffNj1cDjLrpwfVxfs+T77D8b/5FHvjcdSP/exGLrc0eegdvi\nAfwacD9bftX2X4AfXei5zTHfi+nOAj6KLh1OPx43UHNm38Pz6T7APwV8gy2/2ncx3VnaR9PtZfgH\nHvkVqb+i+8B/Bt2hna8Df7KAvc/8tsuS75PuZMMH6PYA/BTdoYnvAS8fsT4/THci2vPoflN8Md2x\n4P+x1PsE9qT7EDqELlD9Vr+8smVfdEHuJrqvNv4c3YfhBuDsnd0n3SH3T9N9MD2dLd+bdh+VPueo\n3+LbLqPSJ/AiustQnEL33vSbwIPAEYuxz53+JrYzHnTHJW+j+/rbWuDQhZ7TVua6me43yJmPV8+o\n+326RH4/3ZnD+894fg/gf9LtXvse3W8sPzajZm+6PQ0b6QLPh4DHL2Dvf8NA+BiVPuk+kP+p7+Gf\ngdfOUrOk++zf6M7v36j+je7D9+3M+CrdUuyT7nDgbD+Xf9y6L7og8FngX+newM8FdtnZfdIFypnP\nTS//wqj0OUf9rTwyfIxEn8Cv012X49/ortXxy4u1T28sJ0mSmlpS53xIkqSlz/AhSZKaMnxIkqSm\nDB+SJKkpw4ckSWrK8CFJkpoyfEiSpKYMH5IkqSnDhyRJasrwIUmSmjJ8SJKkpv4/Pu1UIQWaDRQA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50e8bfd7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(NN.forward(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
